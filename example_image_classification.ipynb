{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификатор изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Data science tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Image manipulations\n",
    "from PIL import Image\n",
    "\n",
    "# Useful for examining network\n",
    "from torchsummary import summary\n",
    "\n",
    "# Timing utility\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# Printing out all outputs\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Местонахождение датасета\n",
    "datadir = ''\n",
    "traindir = datadir + 'train\\\\'\n",
    "validdir = datadir + 'valid\\\\'\n",
    "testdir = datadir + 'test\\\\'\n",
    "\n",
    "save_file_name = 'vgg16-transfer-4.pt'\n",
    "checkpoint_path = 'vgg16-transfer-4.pth'\n",
    "\n",
    "# Изменение для установки оборудования\n",
    "batch_size = 16\n",
    "\n",
    "# Можно ли тренироваться на gpu\n",
    "train_on_gpu = cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')\n",
    "multi_gpu = False\n",
    "\n",
    "# Количество графических процессоров\n",
    "if train_on_gpu:\n",
    "    gpu_count = cuda.device_count()\n",
    "    print(f'{gpu_count} gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False\n",
    "        \n",
    "    print(f'Support multi gpu {multi_gpu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Empty lists\n",
    "categories = []\n",
    "img_categories = []\n",
    "n_train = []\n",
    "n_valid = []\n",
    "n_test = []\n",
    "hs = []\n",
    "ws = []\n",
    "\n",
    "# Iterate through each category\n",
    "for d in os.listdir(traindir):\n",
    "    categories.append(d)\n",
    "\n",
    "    # Number of each image\n",
    "    train_imgs = os.listdir(traindir + d)\n",
    "    valid_imgs = os.listdir(validdir + d)\n",
    "    test_imgs = os.listdir(testdir + d)\n",
    "    n_train.append(len(train_imgs))\n",
    "    n_valid.append(len(valid_imgs))\n",
    "    n_test.append(len(test_imgs))\n",
    "\n",
    "    # Find stats for train images\n",
    "    \n",
    "    for i in train_imgs:\n",
    "        \n",
    "        img_categories.append(d)\n",
    "        img = Image.open(traindir + d + '/' + i)\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        # Shape\n",
    "        hs.append(img_array.shape[0])\n",
    "        ws.append(img_array.shape[1])\n",
    "\n",
    "# Dataframe of categories\n",
    "cat_df = pd.DataFrame({'category': categories,\n",
    "                       'n_train': n_train,\n",
    "                       'n_valid': n_valid, 'n_test': n_test}).\\\n",
    "sort_values('category')\n",
    "\n",
    "# Dataframe of training images\n",
    "image_df = pd.DataFrame({\n",
    "    'category': img_categories,\n",
    "    'height': hs,\n",
    "    'width': ws\n",
    "})\n",
    "\n",
    "cat_df.sort_values('n_train', ascending=False, inplace=True)\n",
    "cat_df.head(10)\n",
    "cat_df.tail(10)\n",
    "len(cat_df)\n",
    "len(image_df)\n",
    "cat_df.index\n",
    "cat_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df.set_index('category')['n_train'].plot.bar(\n",
    "    color='r', figsize=(25, 8))\n",
    "plt.xticks(rotation= 80)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Training Images by Category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only top 50 categories\n",
    "cat_df.set_index('category').iloc[:50]['n_train'].plot.bar(\n",
    "    color='r', figsize=(20, 6))\n",
    "plt.xticks(rotation=80)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Training Images by Category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Распределение размеров изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dsc = image_df.groupby('category').describe()\n",
    "img_dsc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(\n",
    "    img_dsc['height']['mean'], label='Average Height')\n",
    "sns.kdeplot(\n",
    "    img_dsc['width']['mean'], label='Average Width')\n",
    "plt.xlabel('Pixels')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Average Size Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image):\n",
    "    \"\"\"Display image\"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example image\n",
    "x = Image.open(traindir + 'accordion\\\\image_0001.jpg')\n",
    "np.array(x).shape\n",
    "imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Image.open(traindir + 'rhino/image_0004.jpg')\n",
    "np.array(x).shape\n",
    "imshow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предварительная обработка изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразования изображений\n",
    "image_transforms = {\n",
    "    # Train использует увеличение данных\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    # Validation не использует аугментацию\n",
    "    'val':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    # Test не использует аугментацию\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры аугментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_tensor(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # Установите цветовой канал в качестве третьего измерения\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    # Обратные шаги предварительной обработки\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "\n",
    "    # Вырезать значения пикселей изображения\n",
    "    image = np.clip(image, 0, 1)\n",
    "    ax.imshow(image)\n",
    "    plt.axis('off')\n",
    "\n",
    "    return ax, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_img = Image.open(traindir + 'rhino/image_0004.jpg')\n",
    "imshow(ex_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = image_transforms['train']\n",
    "plt.figure(figsize=(24, 24))\n",
    "\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    _ = imshow_tensor(t(ex_img), ax=ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_img = Image.open(traindir + 'rhino/image_0004.jpg')\n",
    "plt.figure(figsize=(24, 24))\n",
    "\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    _ = imshow_tensor(t(ex_img), ax=ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итераторы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets from each folder\n",
    "data = {\n",
    "    'train':\n",
    "    datasets.ImageFolder(root=traindir, transform=image_transforms['train']),\n",
    "    'val':\n",
    "    datasets.ImageFolder(root=validdir, transform=image_transforms['val']),\n",
    "    'test':\n",
    "    datasets.ImageFolder(root=testdir, transform=image_transforms['test'])\n",
    "}\n",
    "\n",
    "# Dataloader iterators\n",
    "dataloaders = {\n",
    "    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(data['val'], batch_size=batch_size, shuffle=False),\n",
    "    'test': DataLoader(data['test'], batch_size=batch_size, shuffle=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainiter = iter(dataloaders['train'])\n",
    "features, labels = next(trainiter)\n",
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainiter = iter(dataloaders['train'])\n",
    "features, labels = next(trainiter)\n",
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(cat_df)\n",
    "print(f'There are {n_classes} different classes.')\n",
    "\n",
    "len(data['train'].classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предварительно обученные модели для классификации изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Процесс использования предварительно обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg19(weights=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заморозка ранних слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze early layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление пользовательского классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = model.classifier[6].in_features\n",
    "\n",
    "# Add on classifier\n",
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.4),\n",
    "    nn.Linear(256, n_classes), nn.LogSoftmax(dim=1))\n",
    "\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перемещение на GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_on_gpu:\n",
    "    model = model.to('cuda')\n",
    "\n",
    "if multi_gpu:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция для загрузки предварительно обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model(model_name):\n",
    "    \"\"\"Retrieve a pre-trained model from torchvision\n",
    "\n",
    "    Params\n",
    "    -------\n",
    "        model_name (str): name of the model (currently only accepts vgg16 and resnet50)\n",
    "\n",
    "    Return\n",
    "    --------\n",
    "        model (PyTorch model): cnn\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if model_name == 'vgg16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "\n",
    "        # Freeze early layers\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        n_inputs = model.classifier[6].in_features\n",
    "\n",
    "        # Add on classifier\n",
    "        model.classifier[6] = nn.Sequential(\n",
    "            nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(256, n_classes), nn.LogSoftmax(dim=1))\n",
    "\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=True)\n",
    "\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        n_inputs = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(256, n_classes), nn.LogSoftmax(dim=1))\n",
    "\n",
    "    # Move to gpu and parallelize\n",
    "    if train_on_gpu:\n",
    "        model = model.to('cuda')\n",
    "\n",
    "    if multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_pretrained_model('vgg16')\n",
    "if multi_gpu:\n",
    "    summary(\n",
    "        model.module,\n",
    "        input_size=(3, 224, 224),\n",
    "        batch_size=batch_size,\n",
    "        device='cuda')\n",
    "else:\n",
    "    summary(\n",
    "        model, input_size=(3, 224, 224), batch_size=batch_size, device='cuda' if train_on_gpu else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_gpu:\n",
    "    print(model.module.classifier[6])\n",
    "else:\n",
    "    print(model.classifier[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сопоставление классов с индексами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.class_to_idx = data['train'].class_to_idx\n",
    "model.idx_to_class = {\n",
    "    idx: class_\n",
    "    for class_, idx in model.class_to_idx.items()\n",
    "}\n",
    "\n",
    "list(model.idx_to_class.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in optimizer.param_groups[0]['params']:\n",
    "    if p.requires_grad:\n",
    "        print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          save_file_name,\n",
    "          max_epochs_stop=3,\n",
    "          n_epochs=20,\n",
    "          print_every=2):\n",
    "    \"\"\"Train a PyTorch Model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): cnn to train\n",
    "        criterion (PyTorch loss): objective to minimize\n",
    "        optimizer (PyTorch optimizier): оптимизатор для вычисления градиентов параметров модели\n",
    "        train_loader (PyTorch dataloader): training dataloader для перебора\n",
    "        valid_loader (PyTorch dataloader): validation dataloader используется для ранней остановки\n",
    "        save_file_name (str ending in '.pt'): путь к файлу для сохранения словаря состояния модели\n",
    "        max_epochs_stop (int): максимальное количество epochs без улучшения потери валидации при ранней остановке\n",
    "        n_epochs (int): maximum number of training epochs\n",
    "        print_every (int): частота of epochs to print training stats\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        model (PyTorch model): trained cnn с лучшими весами\n",
    "        history (DataFrame): history of train and validation loss and accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Раннее прекращение инициализации\n",
    "    epochs_no_improve = 0\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    valid_max_acc = 0\n",
    "    history = []\n",
    "\n",
    "    # Количество уже обученных эпох (при использовании загруженных в модель весов)\n",
    "    try:\n",
    "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
    "    except:\n",
    "        model.epochs = 0\n",
    "        print(f'Начинать обучение с нуля.\\n')\n",
    "\n",
    "    overall_start = timer()\n",
    "\n",
    "    # Main loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # отслеживать training and validation loss each epoch\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_acc = 0\n",
    "        valid_acc = 0\n",
    "\n",
    "        # Приступаем к тренировке\n",
    "        model.train()\n",
    "        start = timer()\n",
    "\n",
    "        # Тренировочный цикл\n",
    "        for ii, (data, target) in enumerate(train_loader):\n",
    "            # Tensors to gpu\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Прогнозируемые выходные данные представляют собой логарифмические вероятности\n",
    "            output = model(data)\n",
    "\n",
    "            # Потеря и обратное распространение градиентов\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Отслеживайте потери train, умножая средние потери на количество примеров в партии\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "            # Вычислите точность, найдя максимальную логарифмическую вероятность\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "            # Нужно преобразовать правильный тензор из int в float в average\n",
    "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "            # Умножьте среднюю точность на количество примеров в пакете\n",
    "            train_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "            # Отслеживать прогресс в обучении\n",
    "            print(\n",
    "                f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
    "                end='\\r')\n",
    "\n",
    "        # После завершения циклов обучения начните проверку\n",
    "        else:\n",
    "            model.epochs += 1\n",
    "\n",
    "            # Не нужно отслеживать градиенты\n",
    "            with torch.no_grad():\n",
    "                # Установить в режим оценки\n",
    "                model.eval()\n",
    "\n",
    "                # Цикл проверки\n",
    "                for data, target in valid_loader:\n",
    "                    # Tensors to gpu\n",
    "                    if train_on_gpu:\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                    # Прямой проход\n",
    "                    output = model(data)\n",
    "\n",
    "                    # Потеря валидации\n",
    "                    loss = criterion(output, target)\n",
    "                    # Умножьте среднюю потерю на количество примеров в партии\n",
    "                    valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                    # Рассчитать точность проверки\n",
    "                    _, pred = torch.max(output, dim=1)\n",
    "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                    accuracy = torch.mean(\n",
    "                        correct_tensor.type(torch.FloatTensor))\n",
    "                    # Умножьте среднюю точность на количество примеров\n",
    "                    valid_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "                # Умножьте среднюю точность на количество примеров\n",
    "                train_loss = train_loss / len(train_loader.dataset)\n",
    "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "                # Вычислите среднюю точность\n",
    "                train_acc = train_acc / len(train_loader.dataset)\n",
    "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
    "\n",
    "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "\n",
    "                # Print training and validation results\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\n",
    "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
    "                    )\n",
    "                    print(\n",
    "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
    "                    )\n",
    "\n",
    "                # Сохраните модель, если потери при проверке уменьшатся\n",
    "                if valid_loss < valid_loss_min:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), save_file_name)\n",
    "                    # Track improvement\n",
    "                    epochs_no_improve = 0\n",
    "                    valid_loss_min = valid_loss\n",
    "                    valid_best_acc = valid_acc\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                # В противном случае увеличьте количество эпох без улучшения\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    # Вызвать раннюю остановку\n",
    "                    if epochs_no_improve >= max_epochs_stop:\n",
    "                        print(\n",
    "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "                        )\n",
    "                        total_time = timer() - overall_start\n",
    "                        print(\n",
    "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
    "                        )\n",
    "\n",
    "                        # Load the best state dict\n",
    "                        model.load_state_dict(torch.load(save_file_name))\n",
    "                        # Attach the optimizer\n",
    "                        model.optimizer = optimizer\n",
    "\n",
    "                        # Format history\n",
    "                        history = pd.DataFrame(\n",
    "                            history,\n",
    "                            columns=[\n",
    "                                'train_loss', 'valid_loss', 'train_acc',\n",
    "                                'valid_acc'\n",
    "                            ])\n",
    "                        return model, history\n",
    "\n",
    "    # Attach the optimizer\n",
    "    model.optimizer = optimizer\n",
    "    # Запишите общее время и распечатайте статистику\n",
    "    total_time = timer() - overall_start\n",
    "    print(\n",
    "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "    )\n",
    "    print(\n",
    "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
    "    )\n",
    "    # Format history\n",
    "    history = pd.DataFrame(\n",
    "        history,\n",
    "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dataloaders['train'],\n",
    "    dataloaders['val'],\n",
    "    save_file_name=save_file_name,\n",
    "    max_epochs_stop=5,\n",
    "    n_epochs=30,\n",
    "    print_every=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Результатаы тренировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_loss', 'valid_loss']:\n",
    "    plt.plot(\n",
    "        history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Negative Log Likelihood')\n",
    "plt.title('Training and Validation Losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_acc', 'valid_acc']:\n",
    "    plt.plot(\n",
    "        100 * history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, path):\n",
    "    \"\"\"Save a PyTorch model checkpoint\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): model to save\n",
    "        path (str): location to save model. Must start with `model_name-` and end in '.pth'\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        None, save the `model` to `path`\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model_name = path.split('-')[0]\n",
    "    assert (model_name in ['vgg16', 'resnet50'\n",
    "                           ]), \"Path must have the correct model name\"\n",
    "\n",
    "    # Basic details\n",
    "    checkpoint = {\n",
    "        'class_to_idx': model.class_to_idx,\n",
    "        'idx_to_class': model.idx_to_class,\n",
    "        'epochs': model.epochs,\n",
    "    }\n",
    "\n",
    "    # Извлеките окончательный классификатор и словарь состояний\n",
    "    if model_name == 'vgg16':\n",
    "        # Проверьте, была ли модель распараллелена\n",
    "        if multi_gpu:\n",
    "            checkpoint['classifier'] = model.module.classifier\n",
    "            checkpoint['state_dict'] = model.module.state_dict()\n",
    "        else:\n",
    "            checkpoint['classifier'] = model.classifier\n",
    "            checkpoint['state_dict'] = model.state_dict()\n",
    "\n",
    "    elif model_name == 'resnet50':\n",
    "        if multi_gpu:\n",
    "            checkpoint['fc'] = model.module.fc\n",
    "            checkpoint['state_dict'] = model.module.state_dict()\n",
    "        else:\n",
    "            checkpoint['fc'] = model.fc\n",
    "            checkpoint['state_dict'] = model.state_dict()\n",
    "\n",
    "    # Добавьте оптимизатор\n",
    "    checkpoint['optimizer'] = model.optimizer\n",
    "    checkpoint['optimizer_state_dict'] = model.optimizer.state_dict()\n",
    "\n",
    "    # Сохраните данные в пути\n",
    "    torch.save(checkpoint, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(model, path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка в контрольную точку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(path):\n",
    "    \"\"\"Load a PyTorch model checkpoint\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        path (str): saved model checkpoint. Must start with `model_name-` and end in '.pth'\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        None, save the `model` to `path`\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Получить название модели\n",
    "    model_name = path.split('-')[0]\n",
    "    assert (model_name in ['vgg16', 'resnet50'\n",
    "                           ]), \"Path must have the correct model name\"\n",
    "\n",
    "    # Load in checkpoint\n",
    "    checkpoint = torch.load(path)\n",
    "\n",
    "    if model_name == 'vgg16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        # Убедитесь, что параметры установлены как не поддающиеся обучению\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        model.classifier = checkpoint['classifier']\n",
    "\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        # Убедитесь, что параметры установлены как не поддающиеся обучению\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        model.fc = checkpoint['fc']\n",
    "\n",
    "    # Load in the state dict\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f'{total_params:,} total parameters.')\n",
    "    total_trainable_params = sum(\n",
    "        p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'{total_trainable_params:,} total gradient parameters.')\n",
    "\n",
    "    # Move to gpu\n",
    "    if multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    if train_on_gpu:\n",
    "        model = model.to('cuda')\n",
    "\n",
    "    # Model basics\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    model.idx_to_class = checkpoint['idx_to_class']\n",
    "    model.epochs = checkpoint['epochs']\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = checkpoint['optimizer']\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer = load_checkpoint(path=checkpoint_path)\n",
    "\n",
    "if multi_gpu:\n",
    "    summary(model.module, input_size=(3, 224, 224), batch_size=batch_size)\n",
    "else:\n",
    "    summary(model, input_size=(3, 224, 224), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dataloaders['train'],\n",
    "    dataloaders['val'],\n",
    "    save_file_name=save_file_name,\n",
    "    max_epochs_stop=5,\n",
    "    n_epochs=30,\n",
    "    print_every=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(model, path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    \"\"\"Process an image path into a PyTorch tensor\"\"\"\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    # Resize\n",
    "    img = image.resize((256, 256))\n",
    "\n",
    "    # Center crop\n",
    "    width = 256\n",
    "    height = 256\n",
    "    new_width = 224\n",
    "    new_height = 224\n",
    "\n",
    "    left = (width - new_width) / 2\n",
    "    top = (height - new_height) / 2\n",
    "    right = (width + new_width) / 2\n",
    "    bottom = (height + new_height) / 2\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "\n",
    "    # Convert to numpy, transpose color dimension and normalize\n",
    "    img = np.array(img).transpose((2, 0, 1)) / 256\n",
    "\n",
    "    # Standardization\n",
    "    means = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
    "    stds = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
    "\n",
    "    img = img - means\n",
    "    img = img / stds\n",
    "\n",
    "    img_tensor = torch.Tensor(img)\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = process_image(testdir + 'rhino/image_0023.jpg')\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, image = imshow_tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, image = imshow_tensor(process_image(testdir + 'dalmatian/image_0018.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция для предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    \"\"\"Make a prediction for an image using a trained model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        image_path (str): filename of the image\n",
    "        model (PyTorch model): trained model for inference\n",
    "        topk (int): number of top predictions to return\n",
    "\n",
    "    Returns\n",
    "\n",
    "    \"\"\"\n",
    "    real_class = image_path.split('/')[-2]\n",
    "\n",
    "    # Convert to pytorch tensor\n",
    "    img_tensor = process_image(image_path)\n",
    "\n",
    "    # Resize\n",
    "    if train_on_gpu:\n",
    "        img_tensor = img_tensor.view(1, 3, 224, 224).cuda()\n",
    "    else:\n",
    "        img_tensor = img_tensor.view(1, 3, 224, 224)\n",
    "\n",
    "    # Set to вычисление\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Модель выводит логарифмические вероятности\n",
    "        out = model(img_tensor)\n",
    "        ps = torch.exp(out)\n",
    "\n",
    "        # Найдите лучшие прогнозы\n",
    "        topk, topclass = ps.topk(topk, dim=1)\n",
    "\n",
    "        # Извлеките фактические классы и вероятности\n",
    "        top_classes = [\n",
    "            model.idx_to_class[class_] for class_ in topclass.cpu().numpy()[0]\n",
    "        ]\n",
    "        top_p = topk.cpu().numpy()[0]\n",
    "\n",
    "        return img_tensor.cpu().squeeze(), top_p, top_classes, real_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 100\n",
    "\n",
    "\n",
    "def random_test_image():\n",
    "    \"\"\"Выберите случайное тестовое изображение из каталога тестов\"\"\"\n",
    "    c = np.random.choice(cat_df['category'])\n",
    "    root = testdir + c + '/'\n",
    "    img_path = root + np.random.choice(os.listdir(root))\n",
    "    return img_path\n",
    "\n",
    "\n",
    "_ = imshow_tensor(process_image(random_test_image()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, top_p, top_classes, real_class = predict(random_test_image(), model)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_p, top_classes, real_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, top_p, top_classes, real_class = predict(random_test_image(), model)\n",
    "top_p, top_classes, real_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Display Predictions\n",
    "\n",
    "Эта функция отображает изображение вместе с прогнозами \"topk\" из модели. Заголовок над изображением отображает истинный класс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prediction(image_path, model, topk):\n",
    "    \"\"\"Отображение изображения и предварительных условий из модели\"\"\"\n",
    "\n",
    "    # Get predictions\n",
    "    img, ps, classes, y_obs = predict(image_path, model, topk)\n",
    "    # Convert results to dataframe for plotting\n",
    "    result = pd.DataFrame({'p': ps}, index=classes)\n",
    "\n",
    "    # Show the image\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    ax, img = imshow_tensor(img, ax=ax)\n",
    "\n",
    "    # Set title to be the actual class\n",
    "    ax.set_title(y_obs, size=20)\n",
    "\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    # Plot a bar plot of predictions\n",
    "    result.sort_values('p')['p'].plot.barh(color='blue', edgecolor='k', ax=ax)\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_prediction(random_test_image(), model, topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_prediction(random_test_image(), model, topk=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Точность тестирования\n",
    "\n",
    "Модели идентификации изображений обычно оцениваются по точности topk (например, модель vgg16 получила 28,41% ошибки top1 и 9,62% ошибки top5 на Imagenet). Мы будем оценивать нашу модель по точности top1 и top5, то есть процент предсказаний, которые она делает точно, и процент предсказаний, в которых реальный класс входит в топ-5 реальных классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведенная ниже функция вычисляет точность для прогноза и цели в терминах topk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1, )):\n",
    "    \"\"\"Compute the topk accuracy(s)\"\"\"\n",
    "    if train_on_gpu:\n",
    "        output = output.to('cuda')\n",
    "        target = target.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        # Найдите предсказанные классы и транспонируйте\n",
    "        _, pred = output.topk(k=maxk, dim=1, largest=True, sorted=True)\n",
    "        pred = pred.t()\n",
    "\n",
    "       # Определите прогнозы, равные целевым показателям\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "\n",
    "        # Для каждого k найдите процент правильных\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size).item())\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testiter = iter(dataloaders['test'])\n",
    "# Получите пакет тестовых изображений и меток\n",
    "features, targets = next(testiter)\n",
    "\n",
    "if train_on_gpu:\n",
    "    accuracy(model(features.to('cuda')), targets, topk=(1, 5))\n",
    "else:\n",
    "    accuracy(model(features), targets, topk=(1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция для оценки модели по всем классам¶\n",
    "Следующая функция выполняет итерацию по тестовому набору, чтобы сделать прогнозы для каждого изображения. Он рассчитывает производительность для каждой категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, criterion, topk=(1, 5)):\n",
    "    \"\"\"Measure the performance of a trained PyTorch model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): trained cnn for inference\n",
    "        test_loader (PyTorch DataLoader): test dataloader\n",
    "        topk (tuple of ints): accuracy to measure\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        results (DataFrame): results for each category\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    classes = []\n",
    "    losses = []\n",
    "    # Hold accuracy results\n",
    "    acc_results = np.zeros((len(test_loader.dataset), len(topk)))\n",
    "    i = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Testing loop\n",
    "        for data, targets in test_loader:\n",
    "\n",
    "            # Tensors to gpu\n",
    "            if train_on_gpu:\n",
    "                data, targets = data.to('cuda'), targets.to('cuda')\n",
    "\n",
    "            # Raw model output\n",
    "            out = model(data)\n",
    "            # Iterate through each example\n",
    "            for pred, true in zip(out, targets):\n",
    "                # Find topk accuracy\n",
    "                acc_results[i, :] = accuracy(\n",
    "                    pred.unsqueeze(0), true.unsqueeze(0), topk)\n",
    "                classes.append(model.idx_to_class[true.item()])\n",
    "                # Calculate the loss\n",
    "                loss = criterion(pred.view(1, n_classes), true.view(1))\n",
    "                losses.append(loss.item())\n",
    "                i += 1\n",
    "\n",
    "    # Send results to a dataframe and calculate average across classes\n",
    "    results = pd.DataFrame(acc_results, columns=[f'top{i}' for i in topk])\n",
    "    results['class'] = classes\n",
    "    results['loss'] = losses\n",
    "    results = results.groupby(classes).mean()\n",
    "\n",
    "    return results.reset_index().rename(columns={'index': 'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "# Оцените модель на основе всех обучающих данных\n",
    "results = evaluate(model, dataloaders['test'], criterion)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты испытаний\n",
    "Мы ожидали бы, что модель лучше справится с теми классами, для которых у нее было больше всего обучающих изображений. Мы можем посмотреть, так ли это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.merge(cat_df, left_on='class', right_on='category').\\\n",
    "    drop(columns=['category'])\n",
    "\n",
    "# Plot using seaborn\n",
    "sns.lmplot(\n",
    "    y='top1', x='n_train', data=results, height=6)\n",
    "plt.xlabel('images')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Top 1 Accuracy vs Number of Training Images')\n",
    "plt.ylim(-5, 105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Category with minimum accuracy.')\n",
    "results.loc[results['top1'].idxmin]\n",
    "\n",
    "print('Category with minimum images.')\n",
    "results.loc[results['n_train'].idxmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    y='top5', x='n_train', data=results, height=6)\n",
    "plt.xlabel('images')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Top 5 Accuracy vs Number of Training Images')\n",
    "plt.ylim(-5, 105)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже, существует некоторая взаимосвязь между количеством обучающих изображений и точностью. Однако есть несколько классов с ограниченными изображениями, в которых модель работает довольно хорошо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted column of test images\n",
    "results['weighted'] = results['n_test'] / results['n_test'].sum()\n",
    "\n",
    "# Create weighted accuracies\n",
    "for i in (1, 5):\n",
    "    results[f'weighted_top{i}'] = results['weighted'] * results[f'top{i}']\n",
    "\n",
    "# Find final accuracy accounting for frequencies\n",
    "top1_weighted = results['weighted_top1'].sum()\n",
    "top5_weighted = results['weighted_top5'].sum()\n",
    "loss_weighted = (results['weighted'] * results['loss']).sum()\n",
    "\n",
    "print(f'Final test cross entropy per image = {loss_weighted:.4f}.')\n",
    "print(f'Final test top 1 weighted accuracy = {top1_weighted:.2f}%')\n",
    "print(f'Final test top 5 weighted accuracy = {top5_weighted:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятно, стоит посмотреть на категории, в которых модель является худшей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "croc1 = testdir + 'crocodile/image_0038.jpg'\n",
    "croc2 = testdir + 'crocodile/image_0039.jpg'\n",
    "croc3 = testdir + 'crocodile/image_0040.jpg'\n",
    "\n",
    "display_prediction(croc1, model, 5)\n",
    "display_prediction(croc2, model, 5)\n",
    "display_prediction(croc3, model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учитывая тонкое различие между `crocodile` и `crocodile_head`, я бы сказал, что эта модель работает довольно хорошо! Высшая планка в распознавании изображений - это человеческий уровень, и наша модель почти достигла его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_category(model, category, n=4):\n",
    "    \"\"\"Display predictions for a category    \n",
    "    \"\"\"\n",
    "    category_results = results.loc[results['class'] == category]\n",
    "    print(category_results.iloc[:, :6], '/n')\n",
    "\n",
    "    images = np.random.choice(\n",
    "        os.listdir(testdir + category + '/'), size=4, replace=False)\n",
    "\n",
    "    for img in images:\n",
    "        display_prediction(testdir + category + '/' + img, model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_category(model, 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_category(model, 'mandolin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
